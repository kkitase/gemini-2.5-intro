{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5225d0",
   "metadata": {},
   "source": [
    "# Google Colab ではじめる Gemini API、マルチモーダル機能 (画像、音声、動画、ドキュメント)を試してみよう。\n",
    "\n",
    "`gemini-2.5-flash` のような Gemini モデルは、`client.models.generate_content()` を使用して、単一のプロンプトでテキスト、画像、音声、動画、ドキュメントを処理できます。これにより、さまざまなメディアタイプのコンテンツを理解し、生成できる強力なマルチモーダル AI アプリケーションを開発できます。\n",
    "\n",
    "**主な機能:**\n",
    "- **視覚的理解**: 画像の分析、テキストの抽出、オブジェクトの識別\n",
    "- **音声処理**: 音声の文字起こし、音楽の分析、音声コンテンツの理解\n",
    "- **動画分析**: 動画の要約、キーフレームの抽出、動きの理解\n",
    "- **ドキュメント処理**: PDF からの情報の抽出、レイアウトの理解\n",
    "- **マルチモーダル生成**: テキストプロンプトからの画像と音声の作成\n",
    "\n",
    "以降の解説は、Google Colab で実際にコードを実行しながら進めることを想定していますが、コードと解説を読み進めるだけでも学習できます。\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kkitase/gemini-2.5-findy/blob/main/notebooks/02-jp-multimodal-capabilities.ipynb)\n",
    "\n",
    "## 重要: 環境の準備\n",
    "- [セットアップと認証](https://colab.research.google.com/github/kkitase/gemini-2.5-findy/blob/main/notebooks/00-jp-setup-and-authentication.ipynb#scrollTo=bfd5d261) のセクションを完了していることを確認してください。\n",
    "- もしエラーが出たら、[Gemini in Google Colab](https://colab.research.google.com/github/kkitase/gemini-2.5-findy/blob/main/notebooks/00-jp-setup-and-authentication.ipynb#scrollTo=7d140654) を使い、コードの説明やデバッグをして解決を試みてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49701aee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 学習のためのリポジトリをクローン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kkitase/gemini-2.5-findy.git\n",
    "%cd gemini-2.5-findy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c36a8",
   "metadata": {},
   "source": [
    "## 1. 画像理解: 単一の画像\n",
    "\n",
    "Gemini は、PIL `Image` オブジェクト、画像のローデータ、または File API を使ってアップロードされたファイルなど、複数の形式の画像を分析できます。\n",
    "\n",
    "**各メソッドの使い分け:**\n",
    "- **画像のローデータ**: API やメモリからの画像データを扱う場合\n",
    "- **File API**: 20MB を超える大きな画像や、複数のリクエストで画像を再利用したい場合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a5496",
   "metadata": {},
   "source": [
    "### 画像処理を行う準備\n",
    "画像処理を行うために必要なツールやライブラリのインストールなど、準備をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a43c35",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 画像処理ライブラリPillowをインストール\n",
    "%pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586efdb9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Gemini APIとHTTPリクエスト用のライブラリをインポート\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import requests\n",
    "\n",
    "# 画像処理のためのライブラリをインポート\n",
    "from PIL import Image\n",
    "\n",
    "# メモリ上でバイナリデータを扱うためのライブラリをインポート\n",
    "from io import BytesIO\n",
    "\n",
    "# Google Colabでのユーザーデータを利用するためのライブラリをインポート\n",
    "from google.colab import userdata\n",
    "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "\n",
    "# APIキーでクライアントを作成\n",
    "MODEL_ID = \"gemini-2.5-flash\"\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル画像をダウンロードします\n",
    "!curl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/Cupcakes.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c87459",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### バイナリデータを読み込んで画像解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像ファイルをバイナリモードで開き、その内容を読み込みます\n",
    "with open('image.jpg', 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "# テキストプロンプトと画像データをモデルに送信して、コンテンツを生成します\n",
    "response_specific = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\"これは何の画像ですか？\", \n",
    "            types.Part.from_bytes(data=image_bytes, mime_type=\"image/jpeg\")]\n",
    ")\n",
    "# 生成されたテキストの応答を出力します\n",
    "print(response_specific.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f4880",
   "metadata": {},
   "source": [
    "### File API を使って画像解析\n",
    "20MB を超える大きなペイロードには File API を使用できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecdd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルを File API にアップロードします\n",
    "file_id = client.files.upload(file=\"assets/data/Cupcakes.jpg\")\n",
    "\n",
    "# アップロードしたファイルとプロンプトを送信して、コンテンツを生成します\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\"これは何の画像ですか？\", file_id]\n",
    ")\n",
    "\n",
    "# 生成されたテキストの応答を出力します\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd94c2",
   "metadata": {},
   "source": [
    "> File API を使用すると、プロジェクトごとに最大 20 GB のファイルを保存でき、ファイルごとの最大サイズは 2 GB です。ファイルは 48 時間保存されます。その期間中は API キーでアクセスできますが、API からダウンロードすることはできません。Gemini API が利用可能なすべてのリージョンで無料で利用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f2d01",
   "metadata": {},
   "source": [
    "## 2. 画像理解: 複数の画像\n",
    "\n",
    "Gemini は複数の画像を同時に分析および比較できます。これは、比較分析、視覚的なストーリーテリング、または一連の出来事の理解に強力です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5975f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較したい画像のURLを定義します\n",
    "image_url_1 = \"https://plus.unsplash.com/premium_photo-1694819488591-a43907d1c5cc?fm=jpg&q=60&w=3000&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MXx8Y3V0ZSUyMGRvZ3xlbnwwfHwwfHx8MA%3D%3D\" # 犬\n",
    "image_url_2 = \"https://images.pexels.com/photos/2071882/pexels-photo-2071882.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500\" # 猫\n",
    "\n",
    "# requestsライブラリを使って、URLから画像データを取得します\n",
    "image_response_req_1 = requests.get(image_url_1)\n",
    "image_response_req_2 = requests.get(image_url_2)\n",
    "\n",
    "response_multi = client.models.generate_content(\n",
    "     model=MODEL_ID,\n",
    "     contents=[\n",
    "         \"この2つの画像を比較してください。それぞれの主な被写体は何で、何をしていますか？\",\n",
    "         \"画像 1:\",\n",
    "         types.Part.from_bytes(data=image_response_req_1.content, mime_type=\"image/jpeg\"),\n",
    "         \"画像 2:\",\n",
    "         types.Part.from_bytes(data=image_response_req_2.content, mime_type=\"image/jpeg\")\n",
    "     ]\n",
    " )\n",
    "print(response_multi.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d39ae2",
   "metadata": {},
   "source": [
    "### 演習: 画像からの製品説明\n",
    "\n",
    "Gemini を使用して製品の画像を分析し、機能、使用例、マーケティングスローガンを含む詳細な説明を生成します。\n",
    "\n",
    "タスク:\n",
    "- 製品の画像 URL を見つけます (例: バックパック、マグカップ、電子機器)。\n",
    "- `requests` ライブラリを使用して、URL から画像コンテンツを取得します。\n",
    "- 画像バイトから `types.Part` オブジェクトを作成します。\n",
    "- 製品についてモデルに尋ねるプロンプトを含むテキスト `types.Part` オブジェクトを作成します。\n",
    "- `client.models.generate_content()` を `MODEL_ID` と、テキストプロンプトパートと画像パートを含むリストで呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e63d1",
   "metadata": {},
   "source": [
    "## 3. 音声解析\n",
    "\n",
    "Gemini は、文字起こし、音声コンテンツ解析、話者識別、音声要約のために音声ファイルを処理できます。これは、ポッドキャスト、会議、インタビュー、ボイスメモに特に役立ちます。\n",
    "\n",
    "**サポートされている音声形式**: MP3、WAV、FLAC、AAC、およびその他の一般的な形式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3101b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"assets/data/audio2.mp3\"\n",
    "\n",
    "file_id = client.files.upload(file=file_path)\n",
    "\n",
    "# Gemini APIを使用して構造化された応答を生成する\n",
    "prompt = \"\"\"エピソードのスクリプトを生成してください。タイムスタンプを含め、話者を特定してください。\n",
    "\n",
    "話者:\n",
    "- Speaker 1: セラフィーナ・クローデル（セラフィーナ）\n",
    "- Speaker 2: 天堂 健（けん）\n",
    "\n",
    "例:\n",
    "[00:00] セラフィーナ: こんにちは。\n",
    "[00:02] けん: こんにちは。\n",
    "\n",
    "正しい話者名を含めることが重要です。前に特定した名前を使用してください。話者の名前が本当にわからない場合は、アルファベットの文字で特定してください。たとえば、不明な話者「A」と別の不明な話者「B」がいる場合があります。\n",
    "\n",
    "音楽または短いジングルが再生されている場合は、次のように示してください。\n",
    "[01:02] [MUSIC] または [01:02] [JINGLE]\n",
    "\n",
    "再生されている音楽またはジングルの名前を特定できる場合は、代わりにそれを使用してください。例:\n",
    "[01:02] [Firework by Katy Perry] または [01:02] [The Sofa Shop jingle]\n",
    "\n",
    "他の音が再生されている場合は、その音を特定してみてください。例:\n",
    "[01:02] [Bell ringing]\n",
    "\n",
    "個々のキャプションはそれぞれ非常に短く、最大でも数文程度にしてください。\n",
    "\n",
    "エピソードの終わりを [END] で示してください。\n",
    "\n",
    "太字や斜体などのマークダウン書式は使用しないでください。\n",
    "\n",
    "外国の文字が正しいと確信している場合を除き、英字のみを使用してください。\n",
    "\n",
    "正しい単語を使用し、すべてを正しく綴ることが重要です。ポッドキャストのコンテキストを参考にしてください。\n",
    "ホストが映画、本、有名人などについて話す場合は、映画、本、有名人の名前が正しく綴られていることを確認してください。\"\"\"\n",
    "audio_part = types.Part.from_uri(file_uri=file_id.uri, mime_type=file_id.mime_type)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[prompt, audio_part]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223a1d2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## 4. 動画解析\n",
    "\n",
    "Gemini は動画ファイルを処理して、その内容を理解し、シーンを解析し、オブジェクトとアクションを特定し、詳細な要約を提供できます。\n",
    "\n",
    "**動画機能:**\n",
    "- シーンの分析と要約\n",
    "- オブジェクトとアクションの認識\n",
    "- 時間的理解 (いつ何が起こるか)\n",
    "- コンテンツの抽出と重要な瞬間\n",
    "- YouTube 動画の分析\n",
    "\n",
    "### 保存された動画の解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9841f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動画を表示します\n",
    "from IPython.display import Video\n",
    "video_path = \"assets/data/dear.mp4\"\n",
    "Video(video_path, embed=True, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c743de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 処理を一時停止するための sleep 関数をインポートします\n",
    "from time import sleep\n",
    "\n",
    "# 分析したい動画ファイルのパスを指定します\n",
    "video_path = \"assets/data/dear.mp4\"\n",
    "\n",
    "# 動画ファイルを File API にアップロードします\n",
    "video_file_id = client.files.upload(file=video_path)\n",
    "\n",
    "# ファイルの処理が完了するまで待機する関数を定義します\n",
    "def wait_for_file_ready(file_id):\n",
    "    # ファイルの状態が「PROCESSING」である間、ループを続けます\n",
    "    while file_id.state == \"PROCESSING\":\n",
    "        sleep(1) # 1秒間待機します\n",
    "        # ファイルの最新の状態を取得します\n",
    "        file_id = client.files.get(name=file_id.name)\n",
    "    return file_id\n",
    "\n",
    "# ファイルの準備ができるまで待機します\n",
    "video_file_id = wait_for_file_ready(video_file_id)\n",
    "\n",
    "# 動画に関するプロンプトを作成します\n",
    "prompt = \"この動画について説明してください。\"\n",
    "\n",
    "# 準備ができたファイルから、APIに渡すためのPartオブジェクトを作成します\n",
    "video_part = types.Part.from_uri(file_uri=video_file_id.uri, mime_type=video_file_id.mime_type)\n",
    "\n",
    "# モデルにプロンプトと動画を送信して、コンテンツを生成します\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[prompt, video_part]\n",
    ")\n",
    "\n",
    "# 生成されたテキストの応答を出力します\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35144229",
   "metadata": {},
   "source": [
    "### YouTube 動画の分析\n",
    "\n",
    "Gemini API は直接の YouTube URL 分析をサポートしていて、動画コンテンツ分析に非常に便利です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50081ac8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# YouTube 動画を確認\n",
    "# YouTube動画をノートブックに埋め込むためのライブラリをインポート\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# 表示したいYouTube動画のURLを定義\n",
    "youtube_url = \"https://www.youtube.com/watch?v=CN_a-uSK67s\"\n",
    "\n",
    "# URLから動画IDを抽出\n",
    "video_id = youtube_url.split(\"v=\")[1]\n",
    "\n",
    "# 動画IDを使って、動画を埋め込み表示\n",
    "YouTubeVideo(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989735ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTune 動画を解析\n",
    "# 分析したいYouTube動画のURLを定義\n",
    "youtube_url = \"https://www.youtube.com/watch?v=CN_a-uSK67s\"\n",
    "\n",
    "# URLからAPIに渡すためのPartオブジェクトを作成します\n",
    "youtube_part = genai.types.Part(\n",
    "    file_data=genai.types.FileData(file_uri=youtube_url)\n",
    ")\n",
    "# 動画に関する具体的な質問をプロンプトとして作成\n",
    "prompt = \"\"\"この動画について、200 字でまとめて。\n",
    "また、動画の中で湯呑みの画像が出てくるタイムスタンプを教えて。\"\"\"\n",
    "\n",
    "# モデルにプロンプトと動画を送信して、コンテンツを生成\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[prompt, youtube_part]\n",
    ")\n",
    "\n",
    "# 生成されたテキストの応答を出力します\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1a0d6",
   "metadata": {},
   "source": [
    "## 5. PDF/ドキュメントファイルの操作\n",
    "\n",
    "Gemini は PDF などドキュメントの情報を抽出できるため、ドキュメント分析、データ抽出、コンテンツ要約に優れています。\n",
    "\n",
    "**一般的な使用例:**\n",
    "- 請求書の処理とデータ抽出\n",
    "- 契約書の分析と要約\n",
    "- 研究論文の分析\n",
    "- フォームの処理と検証\n",
    "- ドキュメントの分類とルーティング\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15965743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析したいPDFファイルのパスを指定\n",
    "pdf_file_path = \"assets/data/komeda.pdf\"\n",
    "\n",
    "# PDFファイルをFile APIにアップロード\n",
    "pdf_file_id = client.files.upload(file=pdf_file_path)\n",
    "\n",
    "# PDFに関する質問をプロンプトとして作成\n",
    "prompt = \"支払総額はいくらですか？\"\n",
    "\n",
    "# アップロードしたファイルから、APIに渡すためのPartオブジェクトを作成\n",
    "pdf_part = types.Part.from_uri(file_uri=pdf_file_id.uri, mime_type=pdf_file_id.mime_type)\n",
    "\n",
    "# モデルにプロンプトとPDFを送信して、コンテンツを生成\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[prompt, pdf_part]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629ee5a",
   "metadata": {},
   "source": [
    "## 6. コード\n",
    "\n",
    "Gemini はコードの理解と生成にも大変優れています。[gitingest](https://github.com/cyclotruc/gitingest) を使用して GitHub リポジトリとチャットしてみましょう。gitingest は、GitHub リポジトリのデータを抽出し、LLM が理解できるようなデータに変換するためのPythonスクリプトです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09305c81",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%pip install gitingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80d804",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from gitingest import ingest_async\n",
    "\n",
    "summary, tree, content = await ingest_async(\"https://github.com/google-gemini/veo-3-gemini-api-quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295ffff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d103356",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f059739",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"このリポジトリが何についてのものか説明してください:\n",
    "\n",
    "コード:\n",
    "{content}\n",
    "\"\"\"\n",
    "\n",
    "chat = client.chats.create(model=MODEL_ID)\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b3020",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(\"スキーマはどのように定義されていますか？\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"\"\"すべてのスキーマルートを更新して、Imagen 4 通常モデル `imagen-4.0-generate-001` を使用するようにしてください。\n",
    "コメントも日本語で追加してください。\n",
    "更新されたファイルのみを返してください。\"\"\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b42fa9",
   "metadata": {},
   "source": [
    "## 7. 画像生成\n",
    "\n",
    "Gemini の画像生成機能を使用して、高品質の画像を生成します。この機能は、ビジュアルコンテンツ、プロトタイプ、マーケティング資料、クリエイティブプロジェクトの作成に最適です。\n",
    "\n",
    "**画像生成機能:**\n",
    "- テキストから画像への生成\n",
    "- プロンプトによるスタイルの制御\n",
    "- 高解像度出力\n",
    "- 信頼性のための SynthID ウォーターマーク\n",
    "- 複数のアスペクト比とサイズ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像処理のためのライブラリをインポート\n",
    "from PIL import Image\n",
    "# メモリ上でバイナリデータを扱うためのライブラリをインポート\n",
    "from io import BytesIO\n",
    "\n",
    "# 画像生成のためのプロンプトを定義\n",
    "prompt_text = \"猫の写真\"\n",
    "\n",
    "# 画像生成モデルを呼び出して、コンテンツを生成\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-preview-image-generation\", # 画像生成専用のモデルID\n",
    "    contents=prompt_text,\n",
    "    config=types.GenerateContentConfig(\n",
    "      # 応答にテキストと画像の両方を含めるように指定します\n",
    "      response_modalities=['TEXT', 'IMAGE']\n",
    "    )\n",
    ")\n",
    "\n",
    "# 応答には複数のパート（テキストや画像など）が含まれている可能性があるため、ループで処理します\n",
    "for part in response.candidates[0].content.parts:\n",
    "  # パートがテキストの場合\n",
    "  if part.text is not None:\n",
    "    print(f\"テキスト応答: {part.text}\")\n",
    "  # パートが画像データの場合\n",
    "  elif part.inline_data is not None and part.inline_data.mime_type.startswith('image/'):\n",
    "      # 画像データを読み込んで開きます\n",
    "      image = Image.open(BytesIO(part.inline_data.data))\n",
    "      # 保存するファイル名を定義します\n",
    "      image_filename = 'gemini_generated_image.png'\n",
    "      # 画像をファイルとして保存します\n",
    "      image.save(image_filename)\n",
    "\n",
    "# 生成された画像を表示します\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d989668",
   "metadata": {},
   "source": [
    "**画像生成のヒント:**\n",
    "- スタイル (写実的、イラスト、漫画など) を具体的に指定する\n",
    "- 照明と雰囲気の記述子を含める\n",
    "- 構図の詳細 (クローズアップ、ワイドショットなど) を指定する\n",
    "- 関連する場合は、アートスタイルや参照に言及する\n",
    "- アスペクト比と解像度のニーズを考慮する\n",
    "\n",
    "> **注**: 生成されたすべての画像には、信頼性検証のために SynthID ウォーターマークが含まれています。詳細は[公式ドキュメント](https://ai.google.dev/gemini-api/docs/image-generation) をご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318578a",
   "metadata": {},
   "source": [
    "## 8. テキスト読み上げ\n",
    "\n",
    "テキストを自然な音声に変換します。この機能により、音声コンテンツ、アクセシビリティ機能、インタラクティブなアプリケーションの作成が可能になります。例えば、オーディオブックや、ニュース記事の読み上げ、また、どんな人でも、情報やサービスを同じように利用しやすくするようなアプリケーションを作成できます。\n",
    "\n",
    "**TTS 機能:**\n",
    "- 複数の音声オプションとスタイル\n",
    "- コントロール可能なペース、トーン、感情\n",
    "- 単一話者および複数話者の音声\n",
    "- 高品質の音声出力\n",
    "- 自然言語による音声指示\n",
    "\n",
    "この例では、`gemini-2.5-flash-preview-tts` モデルを使用して単一話者の音声を生成します。`response_modalities` を `[\"AUDIO\"]` に設定し、`SpeechConfig` を提供する必要があります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f511d8e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 音声データを扱うためのライブラリをインストールします\n",
    "%pip install soundfile numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soundfile: WAVファイルなどの音声データを書き込むためのライブラリ\n",
    "# numpy: 音声データの数値配列を効率的に扱うためのライブラリ\n",
    "# IPython.display.Audio, display: ノートブック上で音声を再生するためのライブラリ\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# 音声に変換したいテキストを定義します。「ゆっくり不気味に言ってください:」の部分は、モデルに声のトーンを指示するプロンプトです\n",
    "text_to_speak = \"\"\"ゆっくり不気味に言ってください:\n",
    "プログラマの天堂健（35）。彼の生きがいは、激務の果てに訪れるサウナでの究極の心身解放――「ととのい」にあった。\n",
    "ある夜、半年がかりのプロジェクトを完遂させた彼は、聖地と崇めるサウナへ向かう。\n",
    "灼熱のサウナ、極冷の水風呂。そして外気浴でリクライニングチェアに身を横たえ、夜空を見上げた瞬間、健の意識は過去最高の多幸感と共に突き抜けた。\n",
    "それが、地球での最後の記憶。\n",
    "次に目覚めた時、そこは鬱蒼とした異世界の森の中だった。\n",
    "\"\"\"\n",
    "\n",
    "# テキスト読み上げ（TTS）専用のモデルを呼び出します\n",
    "# 利用可能な声の一覧から 'Kore' を選択します\n",
    "selected_voice = types.PrebuiltVoiceConfig(\n",
    "    voice_name='Kore'\n",
    ")\n",
    "\n",
    "# 声の詳細設定を作成\n",
    "# 上で選んだ声を voice_config として設定\n",
    "voice_settings = types.VoiceConfig(\n",
    "    prebuilt_voice_config=selected_voice\n",
    ")\n",
    "\n",
    "# 上の声の詳細設定を speech_config として設定\n",
    "speech_settings = types.SpeechConfig(\n",
    "    voice_config=voice_settings\n",
    ")\n",
    "\n",
    "# 応答として「音声(AUDIO)」をリクエストし、スピーチ設定を適用\n",
    "final_config = types.GenerateContentConfig(\n",
    "    response_modalities=[\"AUDIO\"],\n",
    "    speech_config=speech_settings,\n",
    ")\n",
    "\n",
    "# TTS専用モデルに、話す内容(text_to_speak)と最終的な設定(final_config)を渡す。\n",
    "response_tts = client.models.generate_content(\n",
    "   model=\"gemini-2.5-flash-preview-tts\",\n",
    "   contents=text_to_speak,\n",
    "   config=final_config,\n",
    ")\n",
    "\n",
    "# 返ってきた音声データ（バイト列）を、16ビット整数のNumPy配列に変換します\n",
    "audio_array = np.frombuffer(response_tts.candidates[0].content.parts[0].inline_data.data, dtype=np.int16)\n",
    "\n",
    "# NumPy配列を、サンプルレート24000のWAVファイルとして書き出します\n",
    "sf.write(\"generated_speech.wav\", audio_array, 24000)\n",
    "\n",
    "# ノートブック上で再生できるように、音声プレイヤーを表示します\n",
    "display(Audio(\"generated_speech.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22349540",
   "metadata": {},
   "source": [
    "### 演習: アバター生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169bc7a",
   "metadata": {},
   "source": [
    "画像生成とテキスト読み上げ機能を組み合わせて、ビジュアルアバターとその音声紹介を作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a391d3",
   "metadata": {},
   "source": [
    "1.  **アバター画像の生成:**\n",
    "    - アバター画像の説明的なプロンプトを作成します (例: 「アニメ風。サウナハットを被った優しそうなプログラマー」)。\n",
    "    - `client.models.generate_content()` をモデル `gemini-2.0-flash-preview-image-generation` で使用します。\n",
    "    - `GenerateContentConfig` で `response_modalities=['TEXT', 'IMAGE']` を設定します。\n",
    "    - 応答を処理して画像データを抽出します (`mime_type` が `image/` で始まる `part.inline_data.data` から)。\n",
    "    - `PIL.Image` と `BytesIO` を使用して画像を保存します (例: `generated_avatar.png`)。\n",
    "    - 生成された画像を表示します。\n",
    "  \n",
    "2.  **紹介文の作成:**\n",
    "    - アバターの短い紹介文を作成します (例: 「やあ、こんにちは。俺は天堂 健（てんどう けん）。みんなからは気軽に「ケン」って呼ばれているよ。見ての通り、俺はこの世界の人間じゃない。遥か彼方にある「ニホン」っていう場所から、どういうわけかこっちに来てしまったんだ。)。\n",
    "  \n",
    "3.  **紹介文の音声生成:**\n",
    "    - `client.models.generate_content()` をモデル `gemini-2.5-flash-preview-tts` で使用します。\n",
    "    - `contents` には、音声に影響を与えるためにアバターの説明を加えて紹介文を補強できます (例: f\"この画像の説明に基づいて声で言ってください {{your_image_prompt}}: {{your_introduction_text}}\")。\n",
    "    - `GenerateContentConfig` を `response_modalities=[\"AUDIO\"]` で設定します。\n",
    "    - `GenerateContentConfig` 内で `speech_config` を設定して、`prebuilt_voice_config` を選択します (例: `voice_name='Puck'`)。\n",
    "    - 応答を処理して音声データを取得します (`part.inline_data.data` から)。\n",
    "    - 音声データを NumPy 配列に変換し、`soundfile` を使用して WAV ファイルとして保存します (例: `avatar_introduction.wav`)。\n",
    "    - 音声を再生する方法を提供します (例: `IPython.display.Audio`)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de016c4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597b070",
   "metadata": {},
   "source": [
    "# 演習の答え\n",
    "## 3. 演習: 画像からの製品説明\n",
    "\n",
    "Gemini を使用して製品の画像を分析し、機能、使用例、マーケティングスローガンを含む詳細な説明を生成します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"assets/data/debugger.jpg\"\n",
    "\n",
    "with open(image_path, 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68721af9",
   "metadata": {},
   "source": [
    "画像からマーケティングスローガンを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_part = types.Part.from_bytes(data=image_bytes, mime_type=\"image/jpeg\")\n",
    "prompt_text = \"\"\"あなたは、おもちゃメーカーのマーケティングのプロです。\n",
    "この製品の画像を分析し、詳細な説明を生成してください。\n",
    "説明には、主な機能、考えられる使用例、そしてキャッチーなマーケティングスローガンを含めてください。\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[prompt_text, image_part]\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bb4ee",
   "metadata": {},
   "source": [
    "## 8. 演習: アバター生成\n",
    "\n",
    "画像生成とテキスト読み上げ機能を組み合わせて、ビジュアルアバターとその音声紹介を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db045f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_avatar_image = \"アニメ風。日本人男性。サウナハットを被った優しそうなプログラマー\"\n",
    "\n",
    "response_image = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "    contents=prompt_avatar_image,\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_modalities=['TEXT', 'IMAGE'] \n",
    "    )\n",
    ")\n",
    "\n",
    "# Process the response\n",
    "image_saved = False\n",
    "for part in response_image.candidates[0].content.parts:\n",
    "  if part.text is not None:\n",
    "    print(f\"Text response: {part.text}\")\n",
    "  elif part.inline_data is not None and part.inline_data.mime_type.startswith('image/'):\n",
    "      image = Image.open(BytesIO(part.inline_data.data))\n",
    "      image.save(\"generated_avatar.png\")\n",
    "\n",
    "avatar_introduction_text = \"\"\"不気味でしゃがれた声で:\n",
    "やあ、こんにちは。俺は天堂 健（てんどう けん）。みんなからは気軽に「ケン」って呼ばれているよ。見ての通り、俺はこの世界の人間じゃない。遥か彼方にある「ニホン」っていう場所から、どういうわけかこっちに来てしまったんだ。\n",
    "\"\"\"\n",
    "\n",
    "response_speech = client.models.generate_content(\n",
    "   model=\"gemini-2.5-flash-preview-tts\",\n",
    "   contents=f\"Say in an voice based on this image description {prompt_avatar_image}: {avatar_introduction_text}\",\n",
    "   config=types.GenerateContentConfig(\n",
    "      response_modalities=[\"AUDIO\"],\n",
    "      speech_config=types.SpeechConfig(\n",
    "         voice_config=types.VoiceConfig(\n",
    "            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "               voice_name='Puck', # An upbeat voice\n",
    "            )\n",
    "         )\n",
    "      ),\n",
    "   )\n",
    ")\n",
    "\n",
    "audio_array_speech = np.frombuffer(response_speech.candidates[0].content.parts[0].inline_data.data, dtype=np.int16)\n",
    "sf.write(\"avatar_introduction.wav\", audio_array_speech, 24000)\n",
    "\n",
    "display(Image.open(\"generated_avatar.png\"))\n",
    "display(Audio(\"avatar_introduction.wav\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
